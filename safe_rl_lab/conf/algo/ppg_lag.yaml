name: "PPG_Lag"

#PPG specifics
N_pi: 8
E_pi: 2
E_v: 2
E_aux: 6
number_mb_per_epoch: 8
rollout_size: 512
aux_mb_per_N_pi: 16
beta_clone: 1.0

###architecture
a2c_architecture: "separate"
#if shared:
beta_reward: 0.5
beta_cost: 0.5

hidden_sizes: [256, 256]
activation: "tanh"
output_activation: "identity"
weight_initialization_method: "orthogonal"


###lagrange
use_cost: true
cost_limit: 12.5
cost_scaling: 0.5
#pid
k_i: 0.005
k_p: 0.0
k_d: 0.0
d_delay: 15
pid_delta_p_ema_alpha: 0.95
pid_delta_d_ema_alpha: 0.90
sum_norm: True #if adv_total are scaled, the lambda should not be capped
diff_norm: False
penalty_max: 100.0
lagrangian_multiplier_init: 0.0

###optimization
lr: 1e-4
anneal_lr: false
clip_epsilon: 0.2
entropy_coef: 0.00


###normalization
use_max_grad_norm: true
max_grad_norm: 5
normalize_adv_r: true
normalize_adv_c: true

###regularization
use_critic_norm: false
critic_norm_coef: 5000

###gae
gae:
  gamma: 0.99
  lam: 0.95

###early stopping
kl_early_stop: true
target_kl: 0.01