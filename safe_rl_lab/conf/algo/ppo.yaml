name: "PPO"
use_cost: false

#PPO specifics
update_epochs: 8
batch_size: 64
rollout_size: 256

#architecture
a2c_architecture: "separate"
hidden_sizes: [256, 256]
activation: "tanh"
output_activation: "tanh"
weight_initialization_method: "orthogonal"

#optimization
lr: 3e-4
anneal_lr: false
clip_epsilon: 0.2
entropy_coef: 0.0

#normalization
use_max_grad_norm: true
max_grad_norm: 0.5
normalize_adv_r: true
normalize_adv_c: true

#regularization
use_critic_norm: false
critic_norm_coef: 5000

#gae
gae:
  gamma: 0.99
  lam: 0.95

#early stopping
kl_early_stop: true
target_kl: 0.02

