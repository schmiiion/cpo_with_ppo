name: "PPO_Lag"

#PPO Lag specifics
update_epochs: 8
batch_size: 64
rollout_size: 512

#lagrange
use_cost: true
cost_limit: 25
cost_scaling: 1.0
#pid
k_i: 0.01
k_p: 0.0.1
k_d: 0.0
d_delay: 15
pid_delta_p_ema_alpha: 0.95
pid_delta_d_ema_alpha: 0.90
sum_norm: True #if adv_total are scaled, the lambda should not be capped
diff_norm: False
penalty_max: 100.0
lagrangian_multiplier_init: 0.0

#architecture
a2c_architecture: "separate"
hidden_sizes: [256, 256]
activation: "tanh"
output_activation: "identity"
weight_initialization_method: "orthogonal"

#optimization
lr: 1e-4
anneal_lr: false
clip_epsilon: 0.2
entropy_coef: 0.00

#normalization
use_max_grad_norm: true
max_grad_norm: 5
normalize_adv_r: true
normalize_adv_c: true

#regularization
use_critic_norm: false
critic_norm_coef: 5000

#gae
gae:
  gamma: 0.99
  lam: 0.95

#early stopping
kl_early_stop: true
target_kl: 0.01